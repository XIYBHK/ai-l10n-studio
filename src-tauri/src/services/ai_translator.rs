use anyhow::{Result, anyhow};
use reqwest::Client as HttpClient;
use serde::{Deserialize, Serialize};
// use std::collections::HashMap;

use crate::services::term_library::TermLibrary;
use crate::services::translation_memory::TranslationMemory;
use crate::utils::common::is_simple_phrase;
use crate::utils::paths::get_translation_memory_path;

#[cfg(feature = "ts-rs")]
use ts_rs::TS;

// ========== é»˜è®¤ç³»ç»Ÿæç¤ºè¯ (Phase 3) ==========

pub const DEFAULT_SYSTEM_PROMPT: &str = r#"ä¸“ä¸šæ¸¸æˆæœ¬åœ°åŒ–ç¿»è¯‘ã€‚
è§„åˆ™:
1. æœ¯è¯­ä¿ç•™è‹±æ–‡: Actor/Blueprint/Component/Transform/Mesh/Material/Widget/Collision/Array/Float/Integer
2. å›ºå®šç¿»è¯‘: Assetâ†’èµ„äº§, Uniqueâ†’å»é‡, Sliceâ†’æˆªå–, Primitivesâ†’åŸºç¡€ç±»å‹, Constant Speedâ†’åŒ€é€Ÿ, Streamâ†’æµé€, Ascendingâ†’å‡åº, Descendingâ†’é™åº
3. Category: ä¿æŒXToolsç­‰å‘½åç©ºé—´å’Œ|ç¬¦å·, å¦‚ XTools|Sort|Actor â†’ XTools|æ’åº|Actor
4. ä¿ç•™æ‰€æœ‰ç‰¹æ®Šç¬¦å·: |ã€{}ã€%%ã€[]ã€()ã€\nã€\tã€{0}ã€{1}ç­‰
5. ç‰¹æ®Šè¡¨è¾¾: in-placeâ†’åŸåœ°, by valueâ†’æŒ‰å€¼, True/Falseä¿æŒåŸæ ·"#;

// ========== Phase 1: AI ä¾›åº”å•†é…ç½®ç³»ç»Ÿ ==========

/// AI ä¾›åº”å•†ç±»å‹
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[cfg_attr(feature = "ts-rs", derive(TS))]
#[cfg_attr(feature = "ts-rs", ts(export, export_to = "../src/types/generated/"))]
pub enum ProviderType {
    Moonshot,
    OpenAI,
    SparkDesk, // è®¯é£æ˜Ÿç«
    Wenxin,    // ç™¾åº¦æ–‡å¿ƒä¸€è¨€
    Qianwen,   // é˜¿é‡Œé€šä¹‰åƒé—®
    GLM,       // æ™ºè°±AI
    Claude,    // Anthropic
    Gemini,    // Google
}

impl ProviderType {
    /// è·å–é»˜è®¤APIåœ°å€
    pub fn default_url(&self) -> &str {
        match self {
            Self::Moonshot => "https://api.moonshot.cn/v1",
            Self::OpenAI => "https://api.openai.com/v1",
            Self::SparkDesk => "https://spark-api.xf-yun.com/v1",
            Self::Wenxin => "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop",
            Self::Qianwen => "https://dashscope.aliyuncs.com/api/v1",
            Self::GLM => "https://open.bigmodel.cn/api/paas/v4",
            Self::Claude => "https://api.anthropic.com/v1",
            Self::Gemini => "https://generativelanguage.googleapis.com/v1",
        }
    }

    /// è·å–æ˜¾ç¤ºåç§°
    pub fn display_name(&self) -> &str {
        match self {
            Self::Moonshot => "Moonshot AI",
            Self::OpenAI => "OpenAI",
            Self::SparkDesk => "è®¯é£æ˜Ÿç«",
            Self::Wenxin => "ç™¾åº¦æ–‡å¿ƒä¸€è¨€",
            Self::Qianwen => "é˜¿é‡Œé€šä¹‰åƒé—®",
            Self::GLM => "æ™ºè°±AI (GLM)",
            Self::Claude => "Claude (Anthropic)",
            Self::Gemini => "Google Gemini",
        }
    }

    /// è·å–é»˜è®¤æ¨¡å‹
    pub fn default_model(&self) -> &str {
        match self {
            Self::Moonshot => "moonshot-v1-auto",
            Self::OpenAI => "gpt-3.5-turbo",
            Self::SparkDesk => "generalv3.5",
            Self::Wenxin => "ernie-bot-turbo",
            Self::Qianwen => "qwen-turbo",
            Self::GLM => "glm-4",
            Self::Claude => "claude-3-haiku-20240307",
            Self::Gemini => "gemini-pro",
        }
    }

    /// è·å–è¯¥ä¾›åº”å•†çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹
    pub fn get_models(&self) -> Vec<crate::services::ai::ModelInfo> {
        use crate::services::ai::models;
        match self {
            Self::OpenAI => models::get_openai_models(),
            Self::Moonshot => models::get_moonshot_models(),
            Self::SparkDesk => models::get_deepseek_models(), // TODO: åˆ›å»ºç‹¬ç«‹çš„ SparkDesk æ¨¡å‹å®šä¹‰
            Self::Wenxin => models::get_deepseek_models(),    // TODO: åˆ›å»ºç‹¬ç«‹çš„ Wenxin æ¨¡å‹å®šä¹‰
            Self::Qianwen => models::get_deepseek_models(),   // TODO: åˆ›å»ºç‹¬ç«‹çš„ Qianwen æ¨¡å‹å®šä¹‰
            Self::GLM => models::get_deepseek_models(),       // TODO: åˆ›å»ºç‹¬ç«‹çš„ GLM æ¨¡å‹å®šä¹‰
            Self::Claude => models::get_deepseek_models(),    // TODO: åˆ›å»ºç‹¬ç«‹çš„ Claude æ¨¡å‹å®šä¹‰
            Self::Gemini => models::get_deepseek_models(),    // TODO: åˆ›å»ºç‹¬ç«‹çš„ Gemini æ¨¡å‹å®šä¹‰
        }
    }

    /// æ ¹æ®æ¨¡å‹IDè·å–æ¨¡å‹ä¿¡æ¯
    pub fn get_model_info(&self, model_id: &str) -> Option<crate::services::ai::ModelInfo> {
        self.get_models().into_iter().find(|m| m.id == model_id)
    }
}

/// ä»£ç†é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
#[cfg_attr(feature = "ts-rs", derive(TS))]
#[cfg_attr(feature = "ts-rs", ts(export, export_to = "../src/types/generated/"))]
pub struct ProxyConfig {
    pub host: String,
    pub port: u16,
    pub enabled: bool,
}

/// AI é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
#[cfg_attr(feature = "ts-rs", derive(TS))]
#[cfg_attr(feature = "ts-rs", ts(export, export_to = "../src/types/generated/"))]
pub struct AIConfig {
    pub provider: ProviderType,
    pub api_key: String,
    pub base_url: Option<String>, // å¯é€‰çš„è‡ªå®šä¹‰URL
    pub model: Option<String>,    // å¯é€‰çš„è‡ªå®šä¹‰æ¨¡å‹
    pub proxy: Option<ProxyConfig>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[cfg_attr(feature = "ts-rs", derive(TS))]
#[cfg_attr(feature = "ts-rs", ts(export, export_to = "../src/types/generated/"))]
pub struct TokenStats {
    pub input_tokens: u32,
    pub output_tokens: u32,
    pub total_tokens: u32,
    pub cost: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ChatMessage {
    role: String,
    content: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ChatRequest {
    model: String,
    messages: Vec<ChatMessage>,
    temperature: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ChatResponse {
    choices: Vec<Choice>,
    usage: Option<Usage>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Choice {
    message: ChatMessage,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct Usage {
    prompt_tokens: u32,
    completion_tokens: u32,
    total_tokens: u32,
}

#[derive(Debug, Clone)]
pub struct AITranslator {
    client: HttpClient,
    api_key: String,
    base_url: String,
    model: String,
    provider: ProviderType, // ğŸ”§ æ·»åŠ ï¼šä¿å­˜ provider ç±»å‹ç”¨äºè´¹ç”¨è®¡ç®—
    system_prompt: String,
    conversation_history: Vec<ChatMessage>,
    max_history_tokens: usize,
    token_stats: TokenStats,
    use_tm: bool,
    tm: Option<TranslationMemory>,
    // Phase 5: ç›®æ ‡è¯­è¨€ï¼ˆç”¨äºç”Ÿæˆç¿»è¯‘æç¤ºè¯ï¼‰
    target_language: Option<String>,
    // ç»Ÿè®¡ä¿¡æ¯
    pub batch_stats: BatchStats,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BatchStats {
    pub total: usize,
    pub tm_hits: usize,
    pub deduplicated: usize,
    pub ai_translated: usize,
    pub tm_learned: usize,
}

impl AITranslator {
    /// åŸæœ‰æ„é€ å‡½æ•°ï¼ˆPhase 3: æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯ï¼ŒPhase 5: æ”¯æŒç›®æ ‡è¯­è¨€ï¼‰
    pub fn new(
        api_key: String,
        base_url: Option<String>,
        use_tm: bool,
        custom_system_prompt: Option<&str>,
        target_language: Option<String>,
    ) -> Result<Self> {
        let client = HttpClient::new();
        let base_url = base_url.unwrap_or_else(|| "https://api.moonshot.cn/v1".to_string());

        // åŠ è½½æœ¯è¯­åº“å¹¶æ„å»ºç³»ç»Ÿæç¤ºè¯
        let term_library_path = std::env::current_exe()
            .ok()
            .and_then(|p| p.parent().map(|p| p.to_path_buf()))
            .unwrap_or_else(|| std::path::PathBuf::from("."))
            .join("data")
            .join("term_library.json");

        let term_library = TermLibrary::load_from_file(&term_library_path).ok();

        // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥æœ¯è¯­åº“çŠ¶æ€
        if let Some(ref lib) = term_library {
            crate::app_log!(
                "[AITranslator] åŠ è½½æœ¯è¯­åº“: {} æ¡æœ¯è¯­, é£æ ¼æ€»ç»“: {}",
                lib.terms.len(),
                if lib.style_summary.is_some() {
                    "æœ‰"
                } else {
                    "æ— "
                }
            );
        } else {
            crate::app_log!("[AITranslator] æœ¯è¯­åº“æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥");
        }

        let system_prompt = Self::get_system_prompt(custom_system_prompt, term_library.as_ref());

        // ä»æ–‡ä»¶åŠ è½½TMï¼ˆåˆå¹¶å†…ç½®çŸ­è¯­å’Œå·²ä¿å­˜çš„ç¿»è¯‘ï¼‰
        let tm = if use_tm {
            Some(TranslationMemory::new_from_file(
                &get_translation_memory_path(),
            )?)
        } else {
            None
        };

        Ok(Self {
            client,
            api_key,
            base_url,
            model: "moonshot-v1-auto".to_string(),
            provider: ProviderType::Moonshot, // ğŸ”§ é»˜è®¤ä½¿ç”¨ Moonshot
            system_prompt,
            conversation_history: Vec::new(),
            max_history_tokens: 2000,
            token_stats: TokenStats {
                input_tokens: 0,
                output_tokens: 0,
                total_tokens: 0,
                cost: 0.0,
            },
            use_tm,
            tm,
            target_language, // Phase 5: ç›®æ ‡è¯­è¨€
            batch_stats: BatchStats {
                total: 0,
                tm_hits: 0,
                deduplicated: 0,
                ai_translated: 0,
                tm_learned: 0,
            },
        })
    }

    /// ä½¿ç”¨ AIConfig åˆ›å»ºï¼ˆPhase 3: æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯ï¼ŒPhase 5: æ”¯æŒç›®æ ‡è¯­è¨€ï¼‰
    pub fn new_with_config(
        config: AIConfig,
        use_tm: bool,
        custom_system_prompt: Option<&str>,
        target_language: Option<String>,
    ) -> Result<Self> {
        // æ„å»ºHTTPå®¢æˆ·ç«¯ï¼ˆæ”¯æŒä»£ç†ï¼‰
        let client = Self::build_client_with_proxy(config.proxy.clone())?;

        // ä½¿ç”¨è‡ªå®šä¹‰URLæˆ–é»˜è®¤URL
        let base_url = config
            .base_url
            .unwrap_or_else(|| config.provider.default_url().to_string());

        // ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
        let model = config
            .model
            .unwrap_or_else(|| config.provider.default_model().to_string());

        // åŠ è½½æœ¯è¯­åº“å¹¶æ„å»ºç³»ç»Ÿæç¤ºè¯
        let term_library_path = std::env::current_exe()
            .ok()
            .and_then(|p| p.parent().map(|p| p.to_path_buf()))
            .unwrap_or_else(|| std::path::PathBuf::from("."))
            .join("data")
            .join("term_library.json");

        let term_library = TermLibrary::load_from_file(&term_library_path).ok();

        // ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥æœ¯è¯­åº“çŠ¶æ€
        if let Some(ref lib) = term_library {
            crate::app_log!(
                "[AITranslator] åŠ è½½æœ¯è¯­åº“: {} æ¡æœ¯è¯­, é£æ ¼æ€»ç»“: {}",
                lib.terms.len(),
                if lib.style_summary.is_some() {
                    "æœ‰"
                } else {
                    "æ— "
                }
            );
        } else {
            crate::app_log!("[AITranslator] æœ¯è¯­åº“æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥");
        }

        let system_prompt = Self::get_system_prompt(custom_system_prompt, term_library.as_ref());

        // ä»æ–‡ä»¶åŠ è½½TM
        let tm = if use_tm {
            Some(TranslationMemory::new_from_file(
                &get_translation_memory_path(),
            )?)
        } else {
            None
        };

        crate::app_log!(
            "[AIç¿»è¯‘å™¨] ä½¿ç”¨é…ç½®åˆ›å»º: ä¾›åº”å•†={}, æ¨¡å‹={}, ä»£ç†={}",
            config.provider.display_name(),
            model,
            if config.proxy.as_ref().map(|p| p.enabled).unwrap_or(false) {
                "å·²å¯ç”¨"
            } else {
                "æœªå¯ç”¨"
            }
        );

        Ok(Self {
            client,
            api_key: config.api_key,
            base_url,
            model,
            provider: config.provider, // ğŸ”§ ä¿å­˜ provider
            system_prompt,
            conversation_history: Vec::new(),
            max_history_tokens: 2000,
            token_stats: TokenStats {
                input_tokens: 0,
                output_tokens: 0,
                total_tokens: 0,
                cost: 0.0,
            },
            use_tm,
            tm,
            target_language, // Phase 5: ç›®æ ‡è¯­è¨€
            batch_stats: BatchStats {
                total: 0,
                tm_hits: 0,
                deduplicated: 0,
                ai_translated: 0,
                tm_learned: 0,
            },
        })
    }

    /// æ„å»ºæ”¯æŒä»£ç†çš„HTTPå®¢æˆ·ç«¯
    fn build_client_with_proxy(proxy: Option<ProxyConfig>) -> Result<HttpClient> {
        let mut builder = HttpClient::builder();

        // æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨ä»£ç†
        let should_use_proxy = proxy.as_ref().map(|p| p.enabled).unwrap_or(false);

        if should_use_proxy {
            if let Some(proxy_cfg) = proxy {
                let proxy_url = format!("http://{}:{}", proxy_cfg.host, proxy_cfg.port);
                crate::app_log!("[AIç¿»è¯‘å™¨] ä½¿ç”¨ä»£ç†: {}", proxy_url);

                let proxy =
                    reqwest::Proxy::all(&proxy_url).map_err(|e| anyhow!("ä»£ç†é…ç½®é”™è¯¯: {}", e))?;
                builder = builder.proxy(proxy);
            }
        } else {
            // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ˜¾å¼ç¦ç”¨ä»£ç†ï¼Œé˜²æ­¢ reqwest è‡ªåŠ¨è¯»å–ç³»ç»Ÿç¯å¢ƒå˜é‡
            crate::app_log!("[AIç¿»è¯‘å™¨] ä»£ç†å·²ç¦ç”¨ï¼ˆå¿½ç•¥ç³»ç»Ÿä»£ç†è®¾ç½®ï¼‰");
            builder = builder.no_proxy();
        }

        builder
            .build()
            .map_err(|e| anyhow!("HTTPå®¢æˆ·ç«¯æ„å»ºå¤±è´¥: {}", e))
    }

    /// Phase 3: æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¯æŒè‡ªå®šä¹‰ + æœ¯è¯­åº“æ‹¼æ¥ï¼‰
    ///
    /// custom_prompt: ç”¨æˆ·è‡ªå®šä¹‰çš„åŸºç¡€æç¤ºè¯ï¼ˆNoneåˆ™ä½¿ç”¨DEFAULT_SYSTEM_PROMPTï¼‰
    /// term_library: æœ¯è¯­åº“ï¼ˆç”¨äºæ‹¼æ¥é£æ ¼æ€»ç»“ï¼‰
    fn get_system_prompt(
        custom_prompt: Option<&str>,
        term_library: Option<&TermLibrary>,
    ) -> String {
        // ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯æˆ–é»˜è®¤æç¤ºè¯
        let base_prompt = custom_prompt.unwrap_or(DEFAULT_SYSTEM_PROMPT);

        // å¦‚æœæœ‰æœ¯è¯­åº“çš„é£æ ¼æ€»ç»“ï¼Œæ³¨å…¥åˆ°æç¤ºè¯ä¸­
        if let Some(library) = term_library {
            if let Some(style_summary) = &library.style_summary {
                return format!(
                    "{}\n\nã€ç”¨æˆ·ç¿»è¯‘é£æ ¼åå¥½ã€‘ï¼ˆåŸºäº{}æ¡æœ¯è¯­å­¦ä¹ ï¼‰\n{}",
                    base_prompt, style_summary.based_on_terms, style_summary.prompt
                );
            }
        }

        base_prompt.to_string()
    }

    pub async fn translate_batch_with_callbacks(
        &mut self,
        texts: Vec<String>,
        progress_callback: Option<Box<dyn Fn(usize, String) + Send + Sync>>,
        stats_callback: Option<Box<dyn Fn(BatchStats, TokenStats) + Send + Sync>>,
    ) -> Result<Vec<String>> {
        self.translate_batch_internal(texts, progress_callback, Some(stats_callback), None)
            .await
    }

    pub async fn translate_batch(
        &mut self,
        texts: Vec<String>,
        progress_callback: Option<Box<dyn Fn(usize, String) + Send + Sync>>,
    ) -> Result<Vec<String>> {
        let (translations, _sources) = self
            .translate_batch_with_sources(texts, progress_callback, None)
            .await?;
        Ok(translations)
    }

    /// ç¿»è¯‘å¹¶è¿”å›æ¯ä¸ªæ¡ç›®çš„æ¥æº
    pub async fn translate_batch_with_sources(
        &mut self,
        texts: Vec<String>,
        progress_callback: Option<Box<dyn Fn(usize, String) + Send + Sync>>,
        stats_callback: Option<Option<Box<dyn Fn(BatchStats, TokenStats) + Send + Sync>>>,
    ) -> Result<(Vec<String>, Vec<String>)> {
        if texts.is_empty() {
            return Ok((Vec::new(), Vec::new()));
        }

        // åˆå§‹åŒ–æ¥æºè·Ÿè¸ª
        let mut sources = vec![String::from("unknown"); texts.len()];

        let translations = self
            .translate_batch_internal(texts, progress_callback, stats_callback, Some(&mut sources))
            .await?;
        Ok((translations, sources))
    }

    async fn translate_batch_internal(
        &mut self,
        texts: Vec<String>,
        progress_callback: Option<Box<dyn Fn(usize, String) + Send + Sync>>,
        stats_callback: Option<Option<Box<dyn Fn(BatchStats, TokenStats) + Send + Sync>>>,
        mut sources: Option<&mut Vec<String>>, // å¯é€‰çš„æ¥æºè·Ÿè¸ª
    ) -> Result<Vec<String>> {
        if texts.is_empty() {
            return Ok(Vec::new());
        }

        // ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å›è°ƒæ˜¯å¦ä¼ å…¥
        if progress_callback.is_some() {
            crate::app_log!("[translate_batch] âœ… progress_callback å·²ä¼ å…¥");
        } else {
            crate::app_log!("[translate_batch] â„¹ï¸ progress_callback ä¸º Noneï¼ˆå†…éƒ¨è°ƒç”¨ï¼‰");
        }

        // é‡ç½®ç»Ÿè®¡
        self.batch_stats.total = texts.len();
        self.batch_stats.tm_hits = 0;
        self.batch_stats.deduplicated = 0;
        self.batch_stats.ai_translated = 0;
        self.batch_stats.tm_learned = 0;

        // Step 1: ä½¿ç”¨ç¿»è¯‘è®°å¿†åº“è¿›è¡Œé¢„ç¿»è¯‘ + å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
        let mut result = vec![String::new(); texts.len()];
        let mut untranslated_indices = Vec::new();

        let mut unique_texts_ordered: Vec<String> = Vec::new();
        let mut unique_text_to_indices: std::collections::HashMap<String, Vec<usize>> =
            std::collections::HashMap::new();

        if let Some(ref mut tm) = self.tm {
            for (i, text) in texts.iter().enumerate() {
                if let Some(translation) = tm.get_translation(text) {
                    // TMå‘½ä¸­
                    result[i] = translation.clone();
                    self.batch_stats.tm_hits += 1;
                    // è®°å½•æ¥æºä¸ºTM
                    if let Some(ref mut sources_vec) = sources {
                        sources_vec[i] = String::from("tm");
                    }
                    // âŒ æ­¤å¤„ä¸å†ä¸ŠæŠ¥è¿›åº¦ï¼Œé¿å…ä¹±åº
                } else {
                    // TMæœªå‘½ä¸­ï¼Œè®°å½•åˆ°å»é‡map
                    untranslated_indices.push(i);

                    if !unique_text_to_indices.contains_key(text) {
                        unique_texts_ordered.push(text.clone());
                    }
                    unique_text_to_indices
                        .entry(text.clone())
                        .or_insert_with(Vec::new)
                        .push(i);
                }
            }
        } else {
            // æ²¡æœ‰TMï¼Œç›´æ¥å»é‡
            for (i, text) in texts.iter().enumerate() {
                untranslated_indices.push(i);

                if !unique_text_to_indices.contains_key(text) {
                    unique_texts_ordered.push(text.clone());
                }
                unique_text_to_indices
                    .entry(text.clone())
                    .or_insert_with(Vec::new)
                    .push(i);
            }
        }

        let untranslated_count = texts.len() - self.batch_stats.tm_hits;
        let unique_count = unique_texts_ordered.len();
        self.batch_stats.deduplicated = untranslated_count - unique_count;

        // ğŸ“Š TMå¤„ç†å®Œæˆåæ¨é€ç¬¬ä¸€æ¬¡ç»Ÿè®¡æ›´æ–°
        if let Some(ref stats_cb_opt) = stats_callback {
            if let Some(stats_cb) = stats_cb_opt {
                let current_stats = self.batch_stats.clone();
                let current_token_stats = self.token_stats.clone();
                stats_cb(current_stats, current_token_stats);
            }
        }

        // Step 2: åˆ†æ‰¹ç¿»è¯‘å»é‡åçš„æ–‡æœ¬
        if !unique_texts_ordered.is_empty() {
            let unique_list = unique_texts_ordered.clone();
            crate::app_log!(
                "[é¢„å¤„ç†] åŸå§‹{}æ¡ -> TMå‘½ä¸­{}æ¡ -> å¾…ç¿»è¯‘{}æ¡ -> å»é‡èŠ‚çœ{}æ¡",
                texts.len(),
                self.batch_stats.tm_hits,
                untranslated_count,
                self.batch_stats.deduplicated
            );

            const BATCH_SIZE: usize = 25;
            let mut ai_translations = Vec::new();
            let total_batches = (unique_list.len() + BATCH_SIZE - 1) / BATCH_SIZE;

            for (batch_idx, chunk) in unique_list.chunks(BATCH_SIZE).enumerate() {
                crate::app_log!(
                    "[åˆ†æ‰¹ç¿»è¯‘] æ‰¹æ¬¡ {}/{}, å½“å‰æ‰¹{}æ¡",
                    batch_idx + 1,
                    total_batches,
                    chunk.len()
                );

                if batch_idx == 0 {
                    let sample_size = std::cmp::min(3, chunk.len());
                    let sample_texts: Vec<String> =
                        chunk.iter().take(sample_size).cloned().collect();
                    let user_prompt = self.build_user_prompt(&sample_texts);

                    // æ„å»ºæç¤ºè¯æ—¥å¿—ï¼ˆåªæ˜¾ç¤ºå®é™…å‘é€ç»™AIçš„å†…å®¹ï¼Œä¸åŒ…æ‹¬APIå‚æ•°ï¼‰
                    let full_prompt = format!(
                        "ã€System Promptã€‘:\n{}\nã€User Promptã€‘:\n{}",
                        self.current_system_prompt(),
                        user_prompt
                    );

                    let metadata = serde_json::json!({
                        "batch_index": batch_idx + 1,
                        "total_batches": total_batches,
                        "batch_size": chunk.len(),
                        "sample_size": sample_size,
                        "total_items": chunk.len(),
                        "sample_texts": sample_texts,
                        "model": self.model,
                        "temperature": 0.3,
                        "provider": self.provider.display_name(),
                    });
                    crate::services::log_prompt("æ‰¹é‡ç¿»è¯‘", full_prompt, Some(metadata));
                }

                let batch_translations = self.translate_with_ai(chunk.to_vec()).await?;

                if batch_idx == 0 {
                    let logs = crate::services::get_prompt_logs();
                    if let Some(last_idx) = logs.len().checked_sub(1) {
                        if !batch_translations.is_empty() {
                            let sample_size = std::cmp::min(3, batch_translations.len());
                            let sample_results: Vec<String> = batch_translations
                                .iter()
                                .take(sample_size)
                                .cloned()
                                .collect();
                            let mut response = format!(
                                "æ‰¹æ¬¡ç¿»è¯‘ç»“æœï¼ˆæ€» {} æ¡ï¼Œæ˜¾ç¤ºå‰ {} æ¡ï¼‰:\n",
                                batch_translations.len(),
                                sample_size
                            );
                            for (i, result) in sample_results.iter().enumerate() {
                                response.push_str(&format!("{}. {}\n", i + 1, result));
                            }
                            crate::services::update_prompt_response(last_idx, response);
                        }
                    }
                }

                ai_translations.extend(batch_translations);

                if let Some(ref stats_cb_opt) = stats_callback {
                    if let Some(stats_cb) = stats_cb_opt {
                        let current_stats = self.batch_stats.clone();
                        let current_token_stats = self.token_stats.clone();
                        stats_cb(current_stats, current_token_stats);
                    }
                }
            }

            self.batch_stats.ai_translated = unique_list.len();

            // Step 3: å°†ç¿»è¯‘ç»“æœåˆ†å‘åˆ°æ‰€æœ‰å¯¹åº”çš„ç´¢å¼•
            for (unique_text, translation) in unique_list.iter().zip(ai_translations.iter()) {
                if let Some(indices) = unique_text_to_indices.get(unique_text) {
                    for (local_idx, &idx) in indices.iter().enumerate() {
                        result[idx] = translation.clone();
                        // è®°å½•æ¥æºï¼šç¬¬ä¸€ä¸ªæ˜¯AIç¿»è¯‘ï¼Œå…¶ä½™æ˜¯å»é‡
                        if let Some(ref mut sources_vec) = sources {
                            sources_vec[idx] = if local_idx == 0 {
                                String::from("ai")
                            } else {
                                String::from("dedup")
                            };
                        }
                        // âŒ æ­¤å¤„ä¸å†ä¸ŠæŠ¥è¿›åº¦ï¼Œé¿å…ä¹±åº
                    }
                }

                // Step 4: æ›´æ–°ç¿»è¯‘è®°å¿†åº“ï¼ˆæ¯ä¸ªuniqueæ–‡æœ¬åªå­¦ä¹ ä¸€æ¬¡ï¼‰
                if let Some(ref mut tm) = self.tm {
                    if is_simple_phrase(unique_text) && translation.len() <= 50 {
                        let builtin = crate::services::translation_memory::get_builtin_memory();
                        let exists_in_learned = tm.memory.contains_key(unique_text);
                        let exists_in_builtin = builtin.contains_key(unique_text);

                        if !exists_in_learned && !exists_in_builtin {
                            tm.add_translation(unique_text.clone(), translation.clone());
                            self.batch_stats.tm_learned += 1;
                            crate::app_log!("[TMå­¦ä¹ ] {} -> {}", unique_text, translation);
                        } else if exists_in_builtin {
                            crate::app_log!("[TMè·³è¿‡] {} (å·²åœ¨å†…ç½®è¯åº“)", unique_text);
                        } else {
                            crate::app_log!("[TMè·³è¿‡] {} (å·²åœ¨å­¦ä¹ è®°å½•)", unique_text);
                        }
                    }
                }
            }
        }

        // âœ¨ Step 5: ä¿®å¤ - åœ¨æ‰€æœ‰ç¿»è¯‘å®Œæˆåï¼ŒæŒ‰é¡ºåºç»Ÿä¸€ä¸ŠæŠ¥è¿›åº¦
        if let Some(ref callback) = progress_callback {
            for (i, text) in texts.iter().enumerate() {
                if !result[i].is_empty() {
                    callback(i, result[i].clone());
                }
            }
        }

        crate::app_log!(
            "[ç»Ÿè®¡] æ€»{}æ¡ | TMå‘½ä¸­{}æ¡ | å»é‡èŠ‚çœ{}æ¡ | AIç¿»è¯‘{}æ¡ | å­¦ä¹ {}æ¡",
            self.batch_stats.total,
            self.batch_stats.tm_hits,
            self.batch_stats.deduplicated,
            self.batch_stats.ai_translated,
            self.batch_stats.tm_learned
        );

        // ğŸ“Š æœ€ç»ˆç»Ÿè®¡æ›´æ–°ï¼ˆåŒ…å«TMå­¦ä¹ æ•°é‡ï¼‰
        if let Some(ref stats_cb_opt) = stats_callback {
            if let Some(stats_cb) = stats_cb_opt {
                let final_stats = self.batch_stats.clone();
                let final_token_stats = self.token_stats.clone();
                stats_cb(final_stats, final_token_stats);
            }
        }

        Ok(result)
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰çš„ç”¨æˆ·æç¤ºè¯è¿›è¡Œç¿»è¯‘ï¼ˆä¸ä½¿ç”¨æ ‡å‡†æç¤ºè¯æ¨¡æ¿ï¼‰
    /// ç”¨äºç²¾ç¿»ç­‰åœºæ™¯ï¼Œæç¤ºè¯å·²ç»å®Œæ•´æ„å»ºå¥½
    pub async fn translate_with_custom_user_prompt(
        &mut self,
        user_prompt: String,
    ) -> Result<String> {
        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        let messages = if self.conversation_history.is_empty() {
            vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: self.system_prompt.clone(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_prompt.clone(),
                },
            ]
        } else {
            let mut msgs = self.conversation_history.clone();
            msgs.push(ChatMessage {
                role: "user".to_string(),
                content: user_prompt.clone(),
            });
            msgs
        };

        // å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        let request = ChatRequest {
            model: self.model.clone(),
            messages,
            temperature: 0.3,
        };

        // æœ€å¤šé‡è¯•3æ¬¡ï¼ŒæŒ‡æ•°é€€é¿ç­–ç•¥
        let max_retries = 3;
        let mut chat_response: Option<ChatResponse> = None;
        let mut last_error: Option<anyhow::Error> = None;

        for retry in 0..max_retries {
            match self
                .client
                .post(&format!("{}/chat/completions", self.base_url))
                .header("Authorization", format!("Bearer {}", self.api_key))
                .header("Content-Type", "application/json")
                .json(&request)
                .send()
                .await
            {
                Ok(response) => match response.json().await {
                    Ok(parsed) => {
                        chat_response = Some(parsed);
                        break;
                    }
                    Err(e) => {
                        last_error = Some(anyhow::anyhow!("error decoding response body"));
                        if retry < max_retries - 1 {
                            let delay = 2u64.pow(retry as u32);
                            crate::app_log!(
                                "[é‡è¯•] è§£æå“åº”å¤±è´¥ï¼Œ{}ç§’åé‡è¯• ({}/{})",
                                delay,
                                retry + 1,
                                max_retries
                            );
                            tokio::time::sleep(std::time::Duration::from_secs(delay)).await;
                        }
                    }
                },
                Err(e) => {
                    last_error = Some(anyhow::anyhow!("request failed: {}", e));
                    if retry < max_retries - 1 {
                        let delay = 2u64.pow(retry as u32);
                        crate::app_log!(
                            "[é‡è¯•] è¯·æ±‚å¤±è´¥ï¼Œ{}ç§’åé‡è¯• ({}/{})",
                            delay,
                            retry + 1,
                            max_retries
                        );
                        tokio::time::sleep(std::time::Duration::from_secs(delay)).await;
                    }
                }
            }
        }

        let chat_response = chat_response
            .ok_or_else(|| last_error.unwrap_or_else(|| anyhow::anyhow!("æœªçŸ¥é”™è¯¯")))?;

        let assistant_response = chat_response
            .choices
            .first()
            .and_then(|choice| Some(choice.message.content.clone()))
            .ok_or_else(|| anyhow::anyhow!("AIå“åº”ä¸ºç©º"))?;

        // æ›´æ–°å¯¹è¯å†å²ï¼ˆå¦‚æœéœ€è¦ï¼‰
        self.update_conversation_history(&user_prompt, &assistant_response);

        // è¿”å›åŸå§‹å“åº”ï¼ˆä¸åšè§£æï¼‰
        Ok(assistant_response.trim().to_string())
    }

    pub async fn translate_with_ai(&mut self, texts: Vec<String>) -> Result<Vec<String>> {
        // å•å…ƒæµ‹è¯•æ¨¡æ‹Ÿï¼šå¦‚æœ api_key æ˜¯ test_keyï¼Œåˆ™ç›´æ¥è¿”å›åŸæ–‡ä½œä¸ºè¯‘æ–‡ï¼Œè·³è¿‡ç½‘ç»œè¯·æ±‚
        if self.api_key == "test_key" {
            crate::app_log!("[æµ‹è¯•æ¨¡æ‹Ÿ] æ£€æµ‹åˆ° test_keyï¼Œè¿”å›æ¨¡æ‹Ÿç¿»è¯‘ç»“æœã€‚");
            return Ok(texts);
        }

        let user_prompt = self.build_user_prompt(&texts);

        // æ„å»ºæ¶ˆæ¯æ•°ç»„
        let messages = if self.conversation_history.is_empty() {
            vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: self.system_prompt.clone(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_prompt.clone(),
                },
            ]
        } else {
            let mut msgs = self.conversation_history.clone();
            msgs.push(ChatMessage {
                role: "user".to_string(),
                content: user_prompt.clone(),
            });
            msgs
        };

        // å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        let request = ChatRequest {
            model: self.model.clone(),
            messages,
            temperature: 0.3,
        };

        // æœ€å¤šé‡è¯•3æ¬¡ï¼ŒæŒ‡æ•°é€€é¿ç­–ç•¥
        let max_retries = 3;
        let mut chat_response: Option<ChatResponse> = None;
        let mut last_error: Option<anyhow::Error> = None;

        for retry in 0..max_retries {
            match self
                .client
                .post(&format!("{}/chat/completions", self.base_url))
                .header("Authorization", format!("Bearer {}", self.api_key))
                .header("Content-Type", "application/json")
                .json(&request)
                .send()
                .await
            {
                Ok(response) => {
                    let status = response.status();
                    // å…ˆè·å–åŸå§‹æ–‡æœ¬ç”¨äºè°ƒè¯•
                    match response.text().await {
                        Ok(body_text) => {
                            // ç®€åŒ–æ—¥å¿—ï¼šåªè®°å½•å…³é”®ä¿¡æ¯
                            if !status.is_success() {
                                // é”™è¯¯æ—¶è®°å½•å®Œæ•´å“åº”
                                crate::app_log!(
                                    "[APIé”™è¯¯] çŠ¶æ€ç : {}, å“åº”: {}",
                                    status,
                                    &body_text
                                );
                            } else {
                                // æˆåŠŸæ—¶æå–å…³é”®å†…å®¹
                                let summary = if let Ok(json) =
                                    serde_json::from_str::<serde_json::Value>(&body_text)
                                {
                                    // æå– AI è¿”å›çš„å®é™…å†…å®¹
                                    if let Some(content) =
                                        json["choices"][0]["message"]["content"].as_str()
                                    {
                                        format!("å†…å®¹: \"{}\"", content)
                                    } else {
                                        format!(
                                            "tokens: {}, cost: å‚è€ƒusageå­—æ®µ",
                                            json["usage"]["total_tokens"].as_u64().unwrap_or(0)
                                        )
                                    }
                                } else {
                                    // JSON è§£æå¤±è´¥ï¼Œæ˜¾ç¤ºå‰100å­—ç¬¦
                                    if body_text.len() > 100 {
                                        format!(
                                            "{}... ({} å­—ç¬¦)",
                                            &body_text[..100],
                                            body_text.len()
                                        )
                                    } else {
                                        body_text.clone()
                                    }
                                };
                                crate::app_log!("[APIå“åº”] {} OK, {}", status.as_u16(), summary);
                            }

                            // æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
                            if !status.is_success() {
                                // å°è¯•è§£æé€šç”¨é”™è¯¯æ ¼å¼
                                let error_msg = if let Ok(error_json) =
                                    serde_json::from_str::<serde_json::Value>(&body_text)
                                {
                                    // æå–é”™è¯¯ä¿¡æ¯
                                    let extracted_msg = error_json["error"]["message"]
                                        .as_str()
                                        .or_else(|| error_json["message"].as_str())
                                        .or_else(|| error_json["error"].as_str())
                                        .unwrap_or("APIè¯·æ±‚å¤±è´¥");

                                    // æ ¹æ®çŠ¶æ€ç å’Œé”™è¯¯ä¿¡æ¯ç”Ÿæˆå‹å¥½æç¤º
                                    match status.as_u16() {
                                        401 => format!("API Keyæ— æ•ˆæˆ–å·²è¿‡æœŸ: {}", extracted_msg),
                                        403 => format!("APIè®¿é—®è¢«æ‹’ç»: {}", extracted_msg),
                                        429 => {
                                            // 429 å¯èƒ½æ˜¯é¢‘ç‡è¶…é™ï¼Œä¹Ÿå¯èƒ½æ˜¯ä½™é¢ä¸è¶³
                                            if extracted_msg.contains("ä½™é¢")
                                                || extracted_msg.contains("èµ„æºåŒ…")
                                            {
                                                format!("è´¦æˆ·ä½™é¢ä¸è¶³: {}", extracted_msg)
                                            } else {
                                                format!("APIè¯·æ±‚é¢‘ç‡è¶…é™: {}", extracted_msg)
                                            }
                                        }
                                        500..=599 => format!("AIæœåŠ¡å™¨é”™è¯¯: {}", extracted_msg),
                                        _ => format!(
                                            "APIè¯·æ±‚å¤±è´¥({}): {}",
                                            status.as_u16(),
                                            extracted_msg
                                        ),
                                    }
                                } else {
                                    format!("APIè¯·æ±‚å¤±è´¥({}): {}", status.as_u16(), body_text)
                                };

                                crate::app_log!("[é”™è¯¯] {}", error_msg);
                                last_error = Some(anyhow!(error_msg));
                                break; // é”™è¯¯å“åº”ä¸é‡è¯•
                            }

                            // å°è¯•è§£æä¸ºChatResponse
                            match serde_json::from_str::<ChatResponse>(&body_text) {
                                Ok(parsed) => {
                                    chat_response = Some(parsed);
                                    break;
                                }
                                Err(e) => {
                                    let error_msg = format!(
                                        "æ— æ³•è§£æAIå“åº”æ ¼å¼ (æ¨¡å‹: {}): {}\nå“åº”å†…å®¹: {}",
                                        self.model,
                                        e,
                                        if body_text.len() > 500 {
                                            format!("{}...(å·²æˆªæ–­)", &body_text[..500])
                                        } else {
                                            body_text.clone()
                                        }
                                    );
                                    crate::app_log!("[é”™è¯¯] {}", error_msg);
                                    last_error = Some(anyhow!(error_msg));
                                    break; // æ ¼å¼é”™è¯¯ä¸é‡è¯•
                                }
                            }
                        }
                        Err(e) => {
                            let error_msg = format!("è¯»å–å“åº”ä½“å¤±è´¥: {}", e);
                            crate::app_log!("[é”™è¯¯] {}", error_msg);
                            last_error = Some(anyhow!(error_msg));

                            if retry < max_retries - 1 {
                                let delay_secs = 2_u64.pow(retry as u32);
                                tokio::time::sleep(tokio::time::Duration::from_secs(delay_secs))
                                    .await;
                            }
                        }
                    }
                }
                Err(e) => {
                    last_error = Some(e.into());
                    if retry < max_retries - 1 {
                        let delay_secs = 2_u64.pow(retry as u32); // 1s, 2s, 4s
                        crate::app_log!(
                            "[é‡è¯•] ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œ{}ç§’åé‡è¯• ({}/{})",
                            delay_secs,
                            retry + 1,
                            max_retries
                        );
                        tokio::time::sleep(tokio::time::Duration::from_secs(delay_secs)).await;
                    }
                }
            }
        }

        let chat_response = chat_response.ok_or_else(|| {
            last_error.unwrap_or_else(|| anyhow!("ç¿»è¯‘è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯•{}æ¬¡", max_retries))
        })?;

        // æ›´æ–°tokenç»Ÿè®¡ï¼ˆä½¿ç”¨æ–°æ¶æ„ç²¾ç¡®è®¡ç®—ï¼‰
        if let Some(usage) = chat_response.usage {
            self.token_stats.input_tokens += usage.prompt_tokens;
            self.token_stats.output_tokens += usage.completion_tokens;
            self.token_stats.total_tokens += usage.total_tokens;

            // ä½¿ç”¨ ModelInfo è®¡ç®—ç²¾ç¡®æˆæœ¬
            let model_info = self
                .provider
                .get_model_info(&self.model)
                .expect("æ¨¡å‹ä¿¡æ¯å¿…é¡»å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ models/ ç›®å½•ä¸­çš„æ¨¡å‹å®šä¹‰");

            use crate::services::ai::CostCalculator;
            let breakdown = CostCalculator::calculate_openai(
                &model_info,
                usage.prompt_tokens as usize,
                usage.completion_tokens as usize,
                0, // TODO: æ”¯æŒä» API å“åº”ä¸­æå–ç¼“å­˜ token
                0,
            );
            self.token_stats.cost += breakdown.total_cost;
        }

        let assistant_response = chat_response
            .choices
            .first()
            .map(|choice| &choice.message.content)
            .ok_or_else(|| anyhow!("No response content"))?;

        // æ›´æ–°å¯¹è¯å†å²
        self.update_conversation_history(&user_prompt, assistant_response);

        // è§£æç¿»è¯‘ç»“æœ
        let translations = self.parse_translations(assistant_response, &texts)?;

        Ok(translations)
    }

    /// è·å–å½“å‰ä½¿ç”¨çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    pub fn current_system_prompt(&self) -> &str {
        &self.system_prompt
    }

    pub fn build_user_prompt(&self, texts: &[String]) -> String {
        // Phase 5: æ ¹æ®ç›®æ ‡è¯­è¨€ç”Ÿæˆæç¤ºè¯
        let target_lang_instruction = match self.target_language.as_deref() {
            Some("zh-Hans") => "ç®€ä½“ä¸­æ–‡",
            Some("zh-Hant") => "ç¹ä½“ä¸­æ–‡",
            Some("en") => "English",
            Some("ja") => "æ—¥æœ¬èª",
            Some("ko") => "í•œêµ­ì–´",
            Some("fr") => "FranÃ§ais",
            Some("de") => "Deutsch",
            Some("es") => "EspaÃ±ol",
            Some("ru") => "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
            Some("ar") => "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            Some(lang) => lang,
            None => "ç›®æ ‡è¯­è¨€", // é»˜è®¤ï¼ˆæœªæŒ‡å®šè¯­è¨€ï¼‰
        };

        // ç²¾ç®€æç¤ºè¯ï¼šç§»é™¤å†—ä½™è¯´æ˜å’Œç©ºè¡Œ
        let mut prompt = format!("ç¿»è¯‘ä¸º{}ï¼ˆæ¯è¡Œä¸€æ¡ï¼Œå¸¦åºå·ï¼‰:\n", target_lang_instruction);
        for (i, text) in texts.iter().enumerate() {
            prompt.push_str(&format!("{}. {}\n", i + 1, text));
        }
        prompt
    }

    fn update_conversation_history(&mut self, user_prompt: &str, assistant_response: &str) {
        if self.conversation_history.is_empty() {
            self.conversation_history.push(ChatMessage {
                role: "system".to_string(),
                content: self.system_prompt.clone(),
            });
        }

        self.conversation_history.push(ChatMessage {
            role: "user".to_string(),
            content: user_prompt.to_string(),
        });

        self.conversation_history.push(ChatMessage {
            role: "assistant".to_string(),
            content: assistant_response.to_string(),
        });

        // é˜²æ­¢å†å²è¿‡é•¿ï¼šä¿ç•™æœ€è¿‘10è½®å¯¹è¯
        if self.conversation_history.len() > 21 {
            let system_msg = self.conversation_history[0].clone();
            let recent_msgs: Vec<_> = self
                .conversation_history
                .iter()
                .rev()
                .take(20)
                .cloned()
                .collect();
            self.conversation_history = vec![system_msg];
            self.conversation_history
                .extend(recent_msgs.into_iter().rev());
        }
    }

    fn parse_translations(&self, response: &str, original_texts: &[String]) -> Result<Vec<String>> {
        let lines: Vec<&str> = response
            .lines()
            .map(|line| line.trim())
            .filter(|line| !line.is_empty())
            .collect();

        // ä¼˜å…ˆæå–ä»¥æ•°å­—åºå·å¼€å¤´çš„è¡Œï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        let number_prefix_regex = regex::Regex::new(r"^\d+[\.\)ã€:\s]+(.+)$").unwrap();
        let mut translations = Vec::new();

        for line in lines.iter() {
            if let Some(captures) = number_prefix_regex.captures(line) {
                if let Some(content) = captures.get(1) {
                    let translation = content.as_str().trim().to_string();
                    translations.push(translation);
                }
            }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°åºå·æ ¼å¼ï¼Œé™çº§ä¸ºæ‰€æœ‰éç©ºè¡Œï¼ˆå‘åå…¼å®¹ï¼‰
        if translations.is_empty() {
            for line in lines {
                translations.push(line.to_string());
            }
        }

        // âš ï¸ éªŒè¯ç¿»è¯‘æ•°é‡ï¼ˆåªåœ¨å‡ºé”™æ—¶è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼‰
        if translations.len() != original_texts.len() {
            crate::app_log!(
                "[è§£æé”™è¯¯] æœŸæœ›{}æ¡ï¼Œå®é™…{}æ¡\n[AIå“åº”]\n{}",
                original_texts.len(),
                translations.len(),
                response
            );

            return Err(anyhow!(
                "ç¿»è¯‘æ•°é‡ä¸åŒ¹é…ï¼è¯·æ±‚ {} æ¡ï¼Œå®é™…è¿”å› {} æ¡",
                original_texts.len(),
                translations.len()
            ));
        }

        // éªŒè¯ç‰¹æ®Šå­—ç¬¦ä¿ç•™
        for (i, translation) in translations.iter_mut().enumerate() {
            let original = &original_texts[i];

            // æ£€æŸ¥æ¢è¡Œç¬¦
            if original.contains("\\n") && !translation.contains("\\n") {
                if original.ends_with("\\n") && !translation.ends_with("\\n") {
                    translation.push_str("\\n");
                }
            }

            // æ£€æŸ¥å ä½ç¬¦æ•°é‡
            let original_placeholders = self.count_placeholders(original);
            let translation_placeholders = self.count_placeholders(translation);
            if original_placeholders != translation_placeholders {
                crate::app_log!(
                    "[å ä½ç¬¦è­¦å‘Š] '{}' å ä½ç¬¦æ•°é‡ä¸åŒ¹é…ï¼šåŸæ–‡{}ä¸ªï¼Œè¯‘æ–‡{}ä¸ª",
                    original,
                    original_placeholders,
                    translation_placeholders
                );
            }
        }

        Ok(translations)
    }

    fn count_placeholders(&self, text: &str) -> usize {
        let mut count = 0;
        let mut chars = text.chars().peekable();

        while let Some(ch) = chars.next() {
            if ch == '{' {
                if let Some(&next) = chars.peek() {
                    if next.is_ascii_digit() {
                        count += 1;
                    }
                }
            } else if ch == '%' {
                if let Some(&next) = chars.peek() {
                    if next == '%' {
                        count += 1;
                        chars.next(); // è·³è¿‡ç¬¬äºŒä¸ª%
                    }
                }
            }
        }

        count
    }
}

impl AITranslator {
    pub fn get_token_stats(&self) -> &TokenStats {
        &self.token_stats
    }

    pub fn reset_stats(&mut self) {
        self.token_stats = TokenStats {
            input_tokens: 0,
            output_tokens: 0,
            total_tokens: 0,
            cost: 0.0,
        };
    }

    pub fn clear_conversation_history(&mut self) {
        self.conversation_history.clear();
    }

    pub fn get_translation_memory(&self) -> Option<&TranslationMemory> {
        self.tm.as_ref()
    }

    pub fn get_translation_memory_mut(&mut self) -> Option<&mut TranslationMemory> {
        self.tm.as_mut()
    }
}
